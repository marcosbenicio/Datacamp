{"cells":[{"attachments":{},"cell_type":"markdown","id":"bcafb637","metadata":{},"source":["# Data Manipulation with pandas"]},{"cell_type":"code","execution_count":1,"id":"2e25fdd8-4d84-45bc-80f0-949917e00a17","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"scrolled":true},"outputs":[],"source":["# Import packages\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Import datasets\n","homelessness = pd.read_csv(\"data/homelessness.csv\")\n","walmart = pd.read_csv(\"data/walmart.csv\")\n","temperatures = pd.read_csv(\"data/temperatures.csv\")\n","#avocado = pd.read_csv(\"DataSets/avocado.csv\")"]},{"cell_type":"code","execution_count":2,"id":"53965489","metadata":{},"outputs":[],"source":["def printest(coments, value):\n","    return print( \"{} : \\n {} \\n\".format(coments, value) )"]},{"attachments":{},"cell_type":"markdown","id":"d7fdf18e","metadata":{},"source":["# 1. Transforming DataFrames\n","\n","How to inspect DataFrames and perform fundamental manipulations, including sorting rows, subsetting, and adding new columns."]},{"cell_type":"code","execution_count":22,"id":"cc279aa5","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>region</th>\n","      <th>state</th>\n","      <th>individuals</th>\n","      <th>family_members</th>\n","      <th>state_pop</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>East South Central</td>\n","      <td>Alabama</td>\n","      <td>2570.0</td>\n","      <td>864.0</td>\n","      <td>4887681</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Pacific</td>\n","      <td>Alaska</td>\n","      <td>1434.0</td>\n","      <td>582.0</td>\n","      <td>735139</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               region    state  individuals  family_members  state_pop\n","0  East South Central  Alabama       2570.0           864.0    4887681\n","1             Pacific   Alaska       1434.0           582.0     735139"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# Dataframe for chapter 1\n","homelessness.head(2)"]},{"attachments":{},"cell_type":"markdown","id":"5a81c495","metadata":{},"source":["A DataFrames (df) are composed of three partes:\n","- Numpy array for data (`df.values`)\n","- one index to store row (`df.index`)\n","- one index to store column (`df.columns`)"]},{"attachments":{},"cell_type":"markdown","id":"8ad9e511","metadata":{},"source":["## Inspecting"]},{"attachments":{},"cell_type":"markdown","id":"d7210f38-51db-40ea-915c-6d5ee1f450eb","metadata":{},"source":["- `.head()`: returns the first few rows (the “head” of the DataFrame).\n","- `.tail()`: returns the last few rows\n","- `.sample()`: return a random sample of rows from the data frame"]},{"cell_type":"code","execution_count":18,"id":"1de9976e","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["               region       state  individuals  family_members  state_pop\n","0  East South Central     Alabama       2570.0           864.0    4887681\n","1             Pacific      Alaska       1434.0           582.0     735139\n","2            Mountain     Arizona       7259.0          2606.0    7158024\n","3  West South Central    Arkansas       2280.0           432.0    3009733\n","4             Pacific  California     109008.0         20964.0   39461588\n"]}],"source":["# Print the head of the homelessness data \n","print(homelessness.head(5))"]},{"cell_type":"code","execution_count":29,"id":"18baf977","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                region          state  individuals  family_members  state_pop\n","48      South Atlantic  West Virginia       1021.0           222.0    1804291\n","49  East North Central      Wisconsin       2740.0          2167.0    5807406\n","50            Mountain        Wyoming        434.0           205.0     577601\n"]}],"source":["# Print the tail of the homelessness data\n","print(homelessness.tail(3))"]},{"cell_type":"code","execution_count":30,"id":"25f8c609","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                region           state  individuals  family_members  state_pop\n","2             Mountain         Arizona       7259.0          2606.0    7158024\n","25  West North Central        Missouri       3776.0          2107.0    6121623\n","40      South Atlantic  South Carolina       3082.0           851.0    5084156\n"]}],"source":["# Print samples of the homelessness data\n","print(homelessness.sample(3))"]},{"attachments":{},"cell_type":"markdown","id":"6f20cdb1","metadata":{},"source":["- `.info()`: shows information on each of the columns, such as the data type and number of missing values.\n","- `.shape` :returns the number of rows and columns of the DataFrame.\n","- `.describe()`: calculates a few summary statistics for each column."]},{"cell_type":"code","execution_count":7,"id":"1b898bd2","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 51 entries, 0 to 50\n","Data columns (total 5 columns):\n"," #   Column          Non-Null Count  Dtype  \n","---  ------          --------------  -----  \n"," 0   region          51 non-null     object \n"," 1   state           51 non-null     object \n"," 2   individuals     51 non-null     float64\n"," 3   family_members  51 non-null     float64\n"," 4   state_pop       51 non-null     int64  \n","dtypes: float64(2), int64(1), object(2)\n","memory usage: 2.1+ KB\n","None\n"]}],"source":["# Print information about homelessness\n","print(homelessness.info())"]},{"cell_type":"code","execution_count":8,"id":"0b027e21","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(51, 5)\n"]}],"source":["\n","# Print the shape of homelessness\n","print(homelessness.shape)"]},{"cell_type":"code","execution_count":9,"id":"b3c652c6","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["         individuals  family_members     state_pop\n","count      51.000000       51.000000  5.100000e+01\n","mean     7225.784314     3504.882353  6.405637e+06\n","std     15991.025083     7805.411811  7.327258e+06\n","min       434.000000       75.000000  5.776010e+05\n","25%      1446.500000      592.000000  1.777414e+06\n","50%      3082.000000     1482.000000  4.461153e+06\n","75%      6781.500000     3196.000000  7.340946e+06\n","max    109008.000000    52070.000000  3.946159e+07\n"]}],"source":["# Print a description of homelessness\n","print(homelessness.describe())"]},{"attachments":{},"cell_type":"markdown","id":"eea8ab44","metadata":{},"source":["- `.values`: A two-dimensional NumPy array of values.\n","- `.columns`: An index of columns: the column names.\n","- `.index`: An index for the rows: either row numbers or row names."]},{"cell_type":"code","execution_count":12,"id":"9c09d9bb","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[['East South Central' 'Alabama' 2570.0 864.0 4887681]\n"," ['Pacific' 'Alaska' 1434.0 582.0 735139]\n"," ['Mountain' 'Arizona' 7259.0 2606.0 7158024]\n"," ['West South Central' 'Arkansas' 2280.0 432.0 3009733]\n"," ['Pacific' 'California' 109008.0 20964.0 39461588]\n"," ['Mountain' 'Colorado' 7607.0 3250.0 5691287]\n"," ['New England' 'Connecticut' 2280.0 1696.0 3571520]\n"," ['South Atlantic' 'Delaware' 708.0 374.0 965479]\n"," ['South Atlantic' 'District of Columbia' 3770.0 3134.0 701547]\n"," ['South Atlantic' 'Florida' 21443.0 9587.0 21244317]\n"," ['South Atlantic' 'Georgia' 6943.0 2556.0 10511131]\n"," ['Pacific' 'Hawaii' 4131.0 2399.0 1420593]\n"," ['Mountain' 'Idaho' 1297.0 715.0 1750536]\n"," ['East North Central' 'Illinois' 6752.0 3891.0 12723071]\n"," ['East North Central' 'Indiana' 3776.0 1482.0 6695497]\n"," ['West North Central' 'Iowa' 1711.0 1038.0 3148618]\n"," ['West North Central' 'Kansas' 1443.0 773.0 2911359]\n"," ['East South Central' 'Kentucky' 2735.0 953.0 4461153]\n"," ['West South Central' 'Louisiana' 2540.0 519.0 4659690]\n"," ['New England' 'Maine' 1450.0 1066.0 1339057]\n"," ['South Atlantic' 'Maryland' 4914.0 2230.0 6035802]\n"," ['New England' 'Massachusetts' 6811.0 13257.0 6882635]\n"," ['East North Central' 'Michigan' 5209.0 3142.0 9984072]\n"," ['West North Central' 'Minnesota' 3993.0 3250.0 5606249]\n"," ['East South Central' 'Mississippi' 1024.0 328.0 2981020]\n"," ['West North Central' 'Missouri' 3776.0 2107.0 6121623]\n"," ['Mountain' 'Montana' 983.0 422.0 1060665]\n"," ['West North Central' 'Nebraska' 1745.0 676.0 1925614]\n"," ['Mountain' 'Nevada' 7058.0 486.0 3027341]\n"," ['New England' 'New Hampshire' 835.0 615.0 1353465]\n"," ['Mid-Atlantic' 'New Jersey' 6048.0 3350.0 8886025]\n"," ['Mountain' 'New Mexico' 1949.0 602.0 2092741]\n"," ['Mid-Atlantic' 'New York' 39827.0 52070.0 19530351]\n"," ['South Atlantic' 'North Carolina' 6451.0 2817.0 10381615]\n"," ['West North Central' 'North Dakota' 467.0 75.0 758080]\n"," ['East North Central' 'Ohio' 6929.0 3320.0 11676341]\n"," ['West South Central' 'Oklahoma' 2823.0 1048.0 3940235]\n"," ['Pacific' 'Oregon' 11139.0 3337.0 4181886]\n"," ['Mid-Atlantic' 'Pennsylvania' 8163.0 5349.0 12800922]\n"," ['New England' 'Rhode Island' 747.0 354.0 1058287]\n"," ['South Atlantic' 'South Carolina' 3082.0 851.0 5084156]\n"," ['West North Central' 'South Dakota' 836.0 323.0 878698]\n"," ['East South Central' 'Tennessee' 6139.0 1744.0 6771631]\n"," ['West South Central' 'Texas' 19199.0 6111.0 28628666]\n"," ['Mountain' 'Utah' 1904.0 972.0 3153550]\n"," ['New England' 'Vermont' 780.0 511.0 624358]\n"," ['South Atlantic' 'Virginia' 3928.0 2047.0 8501286]\n"," ['Pacific' 'Washington' 16424.0 5880.0 7523869]\n"," ['South Atlantic' 'West Virginia' 1021.0 222.0 1804291]\n"," ['East North Central' 'Wisconsin' 2740.0 2167.0 5807406]\n"," ['Mountain' 'Wyoming' 434.0 205.0 577601]]\n"]}],"source":["# Print the values of homelessness\n","print(homelessness.values)"]},{"cell_type":"code","execution_count":11,"id":"a473ac30","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['region', 'state', 'individuals', 'family_members', 'state_pop'], dtype='object')\n"]}],"source":["# Print the column index of homelessness\n","print(homelessness.columns)"]},{"cell_type":"code","execution_count":10,"id":"b474536f","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RangeIndex(start=0, stop=51, step=1)\n"]}],"source":["# Print the row index of homelessness\n","print(homelessness.index)"]},{"attachments":{},"cell_type":"markdown","id":"a9bd6c5b","metadata":{},"source":["## Sorting values"]},{"attachments":{},"cell_type":"markdown","id":"534cac9d","metadata":{},"source":["`sort_values()` is a method in the Pandas library used to sort a data frame based on one or multiple columns. The sorting can be done in ascending or descending order. By combining `.sort_values()` with `.head()`, you can answer questions in the form, \"What are the top cases where…?\"."]},{"cell_type":"code","execution_count":2,"id":"ff533a1a","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                region          state  individuals  family_members  state_pop\n","32        Mid-Atlantic       New York      39827.0         52070.0   19530351\n","4              Pacific     California     109008.0         20964.0   39461588\n","21         New England  Massachusetts       6811.0         13257.0    6882635\n","9       South Atlantic        Florida      21443.0          9587.0   21244317\n","43  West South Central          Texas      19199.0          6111.0   28628666\n"]}],"source":["# Sort homelessness by descending family members\n","homelessness_fam = homelessness.sort_values(\"family_members\", ascending = False )\n","\n","# Print the top few rows\n","print(homelessness_fam.head())"]},{"cell_type":"code","execution_count":3,"id":"6ad4c84e-0f64-4fe1-824a-01054a338a45","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                region      state  individuals  family_members  state_pop\n","13  East North Central   Illinois       6752.0          3891.0   12723071\n","35  East North Central       Ohio       6929.0          3320.0   11676341\n","22  East North Central   Michigan       5209.0          3142.0    9984072\n","49  East North Central  Wisconsin       2740.0          2167.0    5807406\n","14  East North Central    Indiana       3776.0          1482.0    6695497\n"]}],"source":["# Sort homelessness by region, then descending family members\n","homelessness_reg_fam = homelessness.sort_values(['region', 'family_members'], ascending=[True,False])\n","\n","# Print the top few rows\n","print(homelessness_reg_fam.head())"]},{"attachments":{},"cell_type":"markdown","id":"77e47da4","metadata":{},"source":["## Subseting"]},{"attachments":{},"cell_type":"markdown","id":"8cf8749c","metadata":{},"source":["### Subseting columns"]},{"attachments":{},"cell_type":"markdown","id":"f53a5177","metadata":{},"source":["Square brackets $([~~])$ can be used to select only the columns that matter. To select only \"col_a\" of the DataFrame df, use\n","\n","`df[\"col_a\"]`\n","\n","To select \"col_a\" and \"col_b\" of df, use\n","\n","`df[[\"col_a\", \"col_b\"]]`\n","\n","For example, consider the following cases, where the dataset `homelessness` has the following columns:"]},{"cell_type":"code","execution_count":24,"id":"aabb07ae","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>region</th>\n","      <th>state</th>\n","      <th>individuals</th>\n","      <th>family_members</th>\n","      <th>state_pop</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: [region, state, individuals, family_members, state_pop]\n","Index: []"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["homelessness.head(0)"]},{"cell_type":"code","execution_count":20,"id":"ce5954f5","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["     state  family_members\n","0  Alabama           864.0\n","1   Alaska           582.0\n"]}],"source":["# Select the state and family_members columns\n","state_fam = homelessness[[\"state\",\"family_members\"]]\n","\n","# Print the head of the result\n","print(state_fam.head(2))"]},{"cell_type":"code","execution_count":19,"id":"2bdd98fa","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   individuals    state\n","0       2570.0  Alabama\n","1       1434.0   Alaska\n"]}],"source":["# Select only the individuals and state columns, in that order\n","ind_state = homelessness[[\"individuals\",\"state\"]]\n","\n","# Print the head of the result\n","print(ind_state.head(2))"]},{"attachments":{},"cell_type":"markdown","id":"434eb97d","metadata":{},"source":["### Subsetting rows - Boolean indexing"]},{"attachments":{},"cell_type":"markdown","id":"d083340c","metadata":{},"source":["With Boolean indexing we can use a boolean condition to select rows where the condition is True. Consider the following examples:"]},{"cell_type":"code","execution_count":25,"id":"a2641ecf","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                region       state  individuals  family_members  state_pop\n","4              Pacific  California     109008.0         20964.0   39461588\n","9       South Atlantic     Florida      21443.0          9587.0   21244317\n","32        Mid-Atlantic    New York      39827.0         52070.0   19530351\n","37             Pacific      Oregon      11139.0          3337.0    4181886\n","43  West South Central       Texas      19199.0          6111.0   28628666\n","47             Pacific  Washington      16424.0          5880.0    7523869\n"]}],"source":["# Filter for rows where individuals is greater than 10000\n","ind_gt_10k = homelessness[homelessness[\"individuals\"] > 10000]\n","\n","# See the result\n","print(ind_gt_10k)"]},{"cell_type":"code","execution_count":26,"id":"0815f5e7","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["      region       state  individuals  family_members  state_pop\n","2   Mountain     Arizona       7259.0          2606.0    7158024\n","5   Mountain    Colorado       7607.0          3250.0    5691287\n","12  Mountain       Idaho       1297.0           715.0    1750536\n","26  Mountain     Montana        983.0           422.0    1060665\n","28  Mountain      Nevada       7058.0           486.0    3027341\n","31  Mountain  New Mexico       1949.0           602.0    2092741\n","44  Mountain        Utah       1904.0           972.0    3153550\n","50  Mountain     Wyoming        434.0           205.0     577601\n"]}],"source":["# Filter for rows where region is Mountain\n","mountain_reg = homelessness[ homelessness[\"region\" ] == \"Mountain\" ]\n","\n","# See the result\n","print(mountain_reg)"]},{"cell_type":"code","execution_count":27,"id":"597303ed","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["    region   state  individuals  family_members  state_pop\n","1  Pacific  Alaska       1434.0           582.0     735139\n"]}],"source":["# Filter for rows where family_members is less than 1000 \n","# and region is Pacific\n","fam_lt_1k_pac = homelessness[ (homelessness[\"family_members\"]< 1000)&(homelessness[\"region\"]== \"Pacific\")]\n","\n","# See the result\n","print(fam_lt_1k_pac)"]},{"attachments":{},"cell_type":"markdown","id":"9f588d90","metadata":{},"source":["**Subsetting rows by categorical variables**\n","\n","Subsetting data based on a categorical variable often involves using the \"or\" operator $(~~ | ~~)$ to select rows from multiple categories. "]},{"cell_type":"code","execution_count":37,"id":"34a412cc","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["            region                 state  individuals  family_members  \\\n","7   South Atlantic              Delaware        708.0           374.0   \n","8   South Atlantic  District of Columbia       3770.0          3134.0   \n","9   South Atlantic               Florida      21443.0          9587.0   \n","10  South Atlantic               Georgia       6943.0          2556.0   \n","20  South Atlantic              Maryland       4914.0          2230.0   \n","30    Mid-Atlantic            New Jersey       6048.0          3350.0   \n","\n","    state_pop  \n","7      965479  \n","8      701547  \n","9    21244317  \n","10   10511131  \n","20    6035802  \n","30    8886025  \n"]}],"source":["# Subset for rows in South Atlantic or Mid-Atlantic regions\n","south_mid_atlantic = homelessness[ (homelessness[\"region\"] == \"South Atlantic\" )| (homelessness[\"region\"] == \"Mid-Atlantic\")]\n","\n","# See the result\n","print(south_mid_atlantic.head(6))"]},{"attachments":{},"cell_type":"markdown","id":"33e32e2d","metadata":{},"source":["**`.isin()` method**\n","\n","This can get tedious when you want all states in one of three different regions, for example. Instead, use the `.isin()` method, which will allow you to tackle this problem by writing one condition instead of three separate ones."]},{"cell_type":"code","execution_count":32,"id":"01fd50ae","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["      region       state  individuals  family_members  state_pop\n","2   Mountain     Arizona       7259.0          2606.0    7158024\n","4    Pacific  California     109008.0         20964.0   39461588\n","28  Mountain      Nevada       7058.0           486.0    3027341\n","44  Mountain        Utah       1904.0           972.0    3153550\n"]}],"source":["# The Mojave Desert states\n","canu = [\"California\", \"Arizona\", \"Nevada\", \"Utah\"]\n","\n","# Filter for rows in the Mojave Desert states\n","mojave_homelessness = homelessness[homelessness[\"state\"].isin(canu)]\n","\n","# See the result\n","print(mojave_homelessness)"]},{"attachments":{},"cell_type":"markdown","id":"874fe8b3","metadata":{},"source":["## Adding columns"]},{"cell_type":"code","execution_count":196,"id":"d236010e","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["               region    state  individuals  family_members  state_pop  \\\n","0  East South Central  Alabama       2570.0           864.0    4887681   \n","1             Pacific   Alaska       1434.0           582.0     735139   \n","2            Mountain  Arizona       7259.0          2606.0    7158024   \n","\n","    total  p_individuals  \n","0  3434.0       0.748398  \n","1  2016.0       0.711310  \n","2  9865.0       0.735834  \n"]}],"source":["# Add total col as sum of individuals and family_members\n","homelessness[\"total\"] = homelessness[\"individuals\"] + homelessness[\"family_members\"] \n","\n","# Add p_individuals col as proportion of individuals\n","homelessness[\"p_individuals\"] = homelessness[\"individuals\"]/homelessness[\"total\"]\n","\n","# See the result\n","print(homelessness.head(3))"]},{"attachments":{},"cell_type":"markdown","id":"723e5198","metadata":{},"source":["We can mix and match the four manipulations (**sorting rows, subsetting columns, subsetting rows, and adding new columns**) to answer some questions like, \"Which state has the highest number of homeless individuals per 10,000 people in the state?\" "]},{"cell_type":"code","execution_count":38,"id":"de27b17d","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                   state  indiv_per_10k\n","8   District of Columbia      53.738381\n","11                Hawaii      29.079406\n","4             California      27.623825\n","37                Oregon      26.636307\n","28                Nevada      23.314189\n","47            Washington      21.829195\n","32              New York      20.392363\n"]}],"source":["# Create indiv_per_10k col as homeless individuals per 10k state pop\n","homelessness[\"indiv_per_10k\"] = 10000 * homelessness[\"individuals\"] / homelessness[\"state_pop\"] \n","\n","# Subset rows for indiv_per_10k greater than 20\n","high_homelessness = homelessness[homelessness[\"indiv_per_10k\"]> 20] \n","\n","# Sort high_homelessness by descending indiv_per_10k\n","high_homelessness_srt = high_homelessness.sort_values([\"indiv_per_10k\"] , ascending = False )\n","\n","# From high_homelessness_srt, select the state and indiv_per_10k cols\n","result = high_homelessness_srt[[\"state\", \"indiv_per_10k\"]]\n","\n","# See the result\n","print(result)"]},{"attachments":{},"cell_type":"markdown","id":"4175a7e1","metadata":{},"source":["# 2. Aggregating DataFrames\n","\n","How calculate summary statistics on DataFrame columns, grouped summary statistics and pivot tables."]},{"cell_type":"code","execution_count":18,"id":"df055e5e","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>store</th>\n","      <th>type</th>\n","      <th>department</th>\n","      <th>date</th>\n","      <th>weekly_sales</th>\n","      <th>is_holiday</th>\n","      <th>temperature_c</th>\n","      <th>fuel_price_usd_per_l</th>\n","      <th>unemployment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>2010-02-05</td>\n","      <td>24924.50</td>\n","      <td>False</td>\n","      <td>5.727778</td>\n","      <td>0.679451</td>\n","      <td>8.106</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>2010-03-05</td>\n","      <td>21827.90</td>\n","      <td>False</td>\n","      <td>8.055556</td>\n","      <td>0.693452</td>\n","      <td>8.106</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>2010-04-02</td>\n","      <td>57258.43</td>\n","      <td>False</td>\n","      <td>16.816667</td>\n","      <td>0.718284</td>\n","      <td>7.808</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   store type  department        date  weekly_sales  is_holiday  \\\n","0      1    A           1  2010-02-05      24924.50       False   \n","1      1    A           1  2010-03-05      21827.90       False   \n","2      1    A           1  2010-04-02      57258.43       False   \n","\n","   temperature_c  fuel_price_usd_per_l  unemployment  \n","0       5.727778              0.679451         8.106  \n","1       8.055556              0.693452         8.106  \n","2      16.816667              0.718284         7.808  "]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# Dataframe for chapter 2\n","walmart.head(3)"]},{"attachments":{},"cell_type":"markdown","id":"597f005c","metadata":{},"source":["## Summary statistics\n","\n","Summarize many numbers in one statistic. For example, mean, median, minimum, maximum, and standard deviation are summary statistics that we can get from a dataframe."]},{"attachments":{},"cell_type":"markdown","id":"20de5198","metadata":{},"source":["In the following example we can see that the mean weekly sales amount is almost double the median weekly sales amount. This can tell you that there are a few very high sales weeks that are making the mean so much higher than the median."]},{"cell_type":"code","execution_count":11,"id":"f58e45cc","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 10774 entries, 0 to 10773\n","Data columns (total 9 columns):\n"," #   Column                Non-Null Count  Dtype  \n","---  ------                --------------  -----  \n"," 0   store                 10774 non-null  int64  \n"," 1   type                  10774 non-null  object \n"," 2   department            10774 non-null  int64  \n"," 3   date                  10774 non-null  object \n"," 4   weekly_sales          10774 non-null  float64\n"," 5   is_holiday            10774 non-null  bool   \n"," 6   temperature_c         10774 non-null  float64\n"," 7   fuel_price_usd_per_l  10774 non-null  float64\n"," 8   unemployment          10774 non-null  float64\n","dtypes: bool(1), float64(4), int64(2), object(2)\n","memory usage: 684.0+ KB\n","info : \n"," None \n","\n","mean of weekly_sales : \n"," 23843.95014850566 \n","\n","median of weekly_sales : \n"," 12049.064999999999 \n","\n"]}],"source":["# Print the info about the sales DataFrame\n","printest('info', walmart.info())\n","\n","# Print the mean of weekly_sales\n","printest('mean of weekly_sales',walmart['weekly_sales'].mean())\n","\n","# Print the median of weekly_sales\n","printest('median of weekly_sales', walmart['weekly_sales'].median())"]},{"attachments":{},"cell_type":"markdown","id":"52f57963","metadata":{},"source":["### Efficient summaries with `.agg()`\n","\n","The `.agg()` method allows you to apply your own custom functions to a DataFrame, as well as apply functions to more than one column of a DataFrame at once, making your aggregations super-efficient. For example,\n","\n","`df['column'].agg(f)`\n","\n","will apply the function $f$ to the column named 'column' of the dataframe df.\n"]},{"attachments":{},"cell_type":"markdown","id":"a8df8438","metadata":{},"source":["__Remarks:__ **The interquartile range (IQR)**\n","\n","IQR is a measure of variability, based on dividing a dataset into quartiles. It is defined as the difference between the third quartile ($Q_3$) and the first quartile ($Q_1$).\n","\n","The IQR *gives a sense of how spread* out the values in a dataset are and is a robust measure of dispersion that is not influenced by outliers. It is often used in exploratory data analysis to detect outliers and to summarize a large dataset.\n","\n","- To calculate the IQR\n","  1. first, the data must be sorted in ascending or descending order. \n","  2. $Q_1$ is found by taking the median of the first half of the data, and $Q_3$ is found by taking the median of the second half of the data. \n","  3. Finally, the IQR is calculated as $Q_3 - Q_1$.\n","\n","- For example, if a dataset has the following values: $[3, 5, 7, 8, 9, 11, 14, 15, 16, 17]$, \n","  -  $Q_1$ would be 8 (median of $[3, 5, 7, 8]$), \n","  -  $Q_3$ would be 16 (median of $[14, 15, 16, 17]$), \n","  -   IQR would be $16 - 8 = 8$."]},{"attachments":{},"cell_type":"markdown","id":"266bacc2","metadata":{},"source":["For this case, I create a custom function to calculate the IQR (inter-quartile range) that we are going to use for the columns."]},{"cell_type":"code","execution_count":12,"id":"4c8d74d4","metadata":{},"outputs":[],"source":["# A custom IQR function\n","def iqr(column):\n","    q_3 = column.quantile(0.75)\n","    q_1 = column.quantile(0.25)\n","    return q_3 - q_1"]},{"cell_type":"code","execution_count":14,"id":"ea811b62","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["temperature_c IQR : \n"," 16.583333333333336 \n","\n"]}],"source":["# Print IQR of the temperature_c column\n","printest('temperature_c IQR',walmart['temperature_c'].agg(iqr))"]},{"cell_type":"code","execution_count":16,"id":"a9b89dc0","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["IQR of three columns : \n"," temperature_c           16.583333\n","fuel_price_usd_per_l     0.073176\n","unemployment             0.565000\n","dtype: float64 \n","\n"]}],"source":["# Update to print IQR of temperature_c, fuel_price_usd_per_l, & unemployment\n","printest('IQR of three columns',walmart[[\"temperature_c\", 'fuel_price_usd_per_l', 'unemployment']].agg(iqr))"]},{"cell_type":"code","execution_count":17,"id":"2f532a67","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["IQR and median  : \n","         temperature_c  fuel_price_usd_per_l  unemployment\n","iqr         16.583333              0.073176         0.565\n","median      16.966667              0.743381         8.099 \n","\n"]}],"source":["# Update to print IQR and median of temperature_c, fuel_price_usd_per_l, & unemployment\n","printest('IQR and median ',walmart[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg([iqr, np.median]))"]},{"attachments":{},"cell_type":"markdown","id":"c6e9982d","metadata":{},"source":["## Groupby\n","\n","The basic idea behind `.groupby()` is to split a large dataframe into smaller groups based on the values of one or more columns. The function then applies an aggregation  function `.agg()` to each group, producing a new dataframe that summarizes the information in each group."]},{"attachments":{},"cell_type":"markdown","id":"2b7ca4e0","metadata":{},"source":["Walmart distinguishes three types of stores: \"supercenters,\" \"discount stores,\" and \"neighborhood markets,\" encoded in this dataset as type \"A,\" \"B,\" and \"C.\"  We can calculate the total weekly sales for each type of stores and take the proportions:"]},{"cell_type":"code","execution_count":19,"id":"ce56c0b7","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.9097747 0.0902253 0.       ]\n"]}],"source":["# Calc total weekly sales\n","sales_all = walmart[\"weekly_sales\"].sum()\n","\n","# Subset for type A stores, calc total weekly sales\n","sales_A = walmart[walmart[\"type\"] == \"A\"][\"weekly_sales\"].sum()\n","\n","# Subset for type B stores, calc total weekly sales\n","sales_B = walmart[walmart[\"type\"] == \"B\"][\"weekly_sales\"].sum()\n","\n","# Subset for type C stores, calc total weekly sales\n","sales_C = walmart[walmart[\"type\"] == \"C\"][\"weekly_sales\"].sum()\n","\n","# Get proportion for each type\n","sales_propn_by_type = [sales_A, sales_B, sales_C] / sales_all\n","printest('proportion',sales_propn_by_type)"]},{"attachments":{},"cell_type":"markdown","id":"01b53160","metadata":{},"source":["or in a more sofistecated way, using  `.groupby()` :"]},{"cell_type":"code","execution_count":20,"id":"f5eb3056","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["type\n","A    0.909775\n","B    0.090225\n","Name: weekly_sales, dtype: float64\n"]}],"source":["# Group by type; calc total weekly sales\n","sales_by_type = walmart.groupby(\"type\")[\"weekly_sales\"].sum()\n","\n","# Get proportion for each type\n","sales_propn_by_type = sales_by_type / sum(sales_by_type)\n","print(sales_propn_by_type)"]},{"attachments":{},"cell_type":"markdown","id":"f102b05b","metadata":{},"source":["We saw how `.agg()` method is useful to compute multiple statistics on multiple variables. It also works with `.groupby()` to summarize information of each subset of the data frame of interest."]},{"cell_type":"code","execution_count":21,"id":"19bed92b","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["        amin       amax          mean    median\n","type                                           \n","A    -1098.0  293966.05  23674.667242  11943.92\n","B     -798.0  232558.51  25696.678370  13336.08\n","     unemployment                         fuel_price_usd_per_l            \\\n","             amin   amax      mean median                 amin      amax   \n","type                                                                       \n","A           3.879  8.992  7.972611  8.067             0.664129  1.107410   \n","B           7.170  9.765  9.279323  9.199             0.760023  1.107674   \n","\n","                          \n","          mean    median  \n","type                      \n","A     0.744619  0.735455  \n","B     0.805858  0.803348  \n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\marcos\\AppData\\Local\\Temp\\ipykernel_4848\\87317130.py:8: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n","  unemp_fuel_stats = walmart.groupby(\"type\")[\"unemployment\", \"fuel_price_usd_per_l\"].agg([np.min,np.max,np.mean,np.median])\n"]}],"source":["# For each store type, aggregate weekly_sales: get min, max, mean, and median\n","sales_stats = walmart.groupby(\"type\")['weekly_sales'].agg([np.min,np.max,np.mean,np.median])\n","\n","# Print sales_stats\n","print(sales_stats)\n","\n","# For each store type, aggregate unemployment and fuel_price_usd_per_l: get min, max, mean, and median\n","unemp_fuel_stats = walmart.groupby(\"type\")[\"unemployment\", \"fuel_price_usd_per_l\"].agg([np.min,np.max,np.mean,np.median])\n","\n","# Print unemp_fuel_stats\n","print(unemp_fuel_stats)"]},{"attachments":{},"cell_type":"markdown","id":"3eecefbf","metadata":{},"source":["## Pivot tables\n","\n","Pivot tables allow you to take a multi-dimensional data set and transform it into a two-dimensional data set that is easier to understand and analyze. They can help you identify patterns and relationships in your data, and can be used to create interactive dashboards and reports.\n","\n","A pivot table in Pandas is created using the `.pivot_table` method. You specify the columns of the dataframe to use as the row and column indices, and the values to be aggregated. The values can be aggregated using a variety of functions, such as sum, mean, count, etc. **By default, pivot_table uses the mean as the aggregation function**, but you can specify a different aggregation function using the aggfunc parameter."]},{"attachments":{},"cell_type":"markdown","id":"1aecd8e6","metadata":{},"source":["Pivot tables are the standard way of aggregating data in spreadsheets. In pandas, pivot tables are essentially just another way of performing grouped calculations. That is, the `.pivot_table()` method is just an alternative to `.groupby()`. "]},{"cell_type":"code","execution_count":33,"id":"1fc40c6d","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["type\n","A    23674.667242\n","B    25696.678370\n","Name: weekly_sales, dtype: float64\n"]}],"source":["# mean weekly_sales for each store type \n","mean_sales_by_type = walmart.groupby(\"type\")[\"weekly_sales\"].mean()\n","\n","print(mean_sales_by_type)"]},{"cell_type":"code","execution_count":34,"id":"379214d2","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["      weekly_sales\n","type              \n","A     23674.667242\n","B     25696.678370\n"]}],"source":["# Pivot for mean weekly_sales for each store type\n","mean_sales_by_type = walmart.pivot_table(values = \"weekly_sales\",index = \"type\")\n","\n","# Print mean_sales_by_type\n","print(mean_sales_by_type)"]},{"attachments":{},"cell_type":"markdown","id":"a51a0255","metadata":{},"source":["We can return a pivot table with Multiple statistics "]},{"cell_type":"code","execution_count":27,"id":"c336dbd4","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              mean       median\n","      weekly_sales weekly_sales\n","type                           \n","A     23674.667242     11943.92\n","B     25696.678370     13336.08\n"]}],"source":["# Pivot for mean and median weekly_sales for each store type\n","mean_med_sales_by_type = walmart.pivot_table(values =\"weekly_sales\", index =\"type\", aggfunc =[np.mean,np.median])\n","\n","\n","print(mean_med_sales_by_type)"]},{"attachments":{},"cell_type":"markdown","id":"ac13987e","metadata":{},"source":["or create a pivot table with two variables (columns). For this we need to specify the index, to group elements in rows, and the columns name that wil be used as the column for the pivot table. "]},{"cell_type":"code","execution_count":28,"id":"0043c962","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["is_holiday         False       True\n","type                               \n","A           23768.583523  590.04525\n","B           25751.980533  810.70500\n"]}],"source":["# Pivot for mean weekly_sales by store type and holiday \n","mean_sales_by_type_holiday = walmart.pivot_table(values=\"weekly_sales\", index=\"type\", columns=\"is_holiday\")\n","\n","\n","print(mean_sales_by_type_holiday)"]},{"cell_type":"code","execution_count":29,"id":"ae28203f","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["department            1              2             3             4   \\\n","type                                                                  \n","A           30961.725379   67600.158788  17160.002955  44285.399091   \n","B           44050.626667  112958.526667  30580.655000  51219.654167   \n","\n","department            5             6             7             8   \\\n","type                                                                 \n","A           34821.011364   7136.292652  38454.336818  48583.475303   \n","B           63236.875000  10717.297500  52909.653333  90733.753333   \n","\n","department            9             10  ...            90            91  \\\n","type                                    ...                               \n","A           30120.449924  30930.456364  ...  85776.905909  70423.165227   \n","B           66679.301667  48595.126667  ...  14780.210000  13199.602500   \n","\n","department             92            93            94             95  \\\n","type                                                                   \n","A           139722.204773  53413.633939  60081.155303  123933.787121   \n","B            50859.278333   1466.274167    161.445833   77082.102500   \n","\n","department            96            97            98          99  \n","type                                                              \n","A           21367.042857  28471.266970  12875.423182  379.123659  \n","B            9528.538333   5828.873333    217.428333    0.000000  \n","\n","[2 rows x 80 columns]\n"]}],"source":["# Print mean weekly_sales by department and type; fill missing values with 0\n","print(walmart.pivot_table(values = 'weekly_sales',index = \"type\", columns = 'department', fill_value = 0))"]},{"cell_type":"code","execution_count":30,"id":"82d6f3d9","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["type                   A              B           All\n","department                                           \n","1           30961.725379   44050.626667  32052.467153\n","2           67600.158788  112958.526667  71380.022778\n","3           17160.002955   30580.655000  18278.390625\n","4           44285.399091   51219.654167  44863.253681\n","5           34821.011364   63236.875000  37189.000000\n","...                  ...            ...           ...\n","96          21367.042857    9528.538333  20337.607681\n","97          28471.266970    5828.873333  26584.400833\n","98          12875.423182     217.428333  11820.590278\n","99            379.123659       0.000000    379.123659\n","All         23674.667242   25696.678370  23843.950149\n","\n","[81 rows x 3 columns]\n"]}],"source":["# Print the mean weekly_sales by department and type; fill missing values with 0s; sum all rows and cols\n","print(walmart.pivot_table(values=\"weekly_sales\", index=\"department\", columns=\"type\", fill_value = 0, margins = True))"]},{"attachments":{},"cell_type":"markdown","id":"6c918476","metadata":{},"source":["# 3. Slicing and Indexing DataFrames\n","\n","Indexes are supercharged row and column names. They can be combined with slicing for DataFrame subsetting."]},{"cell_type":"code","execution_count":35,"id":"6f041b34","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>city</th>\n","      <th>country</th>\n","      <th>avg_temp_c</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2000-01-01</td>\n","      <td>Abidjan</td>\n","      <td>Côte D'Ivoire</td>\n","      <td>27.293</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2000-02-01</td>\n","      <td>Abidjan</td>\n","      <td>Côte D'Ivoire</td>\n","      <td>27.685</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2000-03-01</td>\n","      <td>Abidjan</td>\n","      <td>Côte D'Ivoire</td>\n","      <td>29.061</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         date     city        country  avg_temp_c\n","0  2000-01-01  Abidjan  Côte D'Ivoire      27.293\n","1  2000-02-01  Abidjan  Côte D'Ivoire      27.685\n","2  2000-03-01  Abidjan  Côte D'Ivoire      29.061"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["# Dataframe for chapter 3\n","temperatures.head(3)"]},{"attachments":{},"cell_type":"markdown","id":"e641858d","metadata":{},"source":["## Indexes \n","\n","Index can be thought of as the primary key for a DataFrame, similar to how a primary key is used in a relational database. \n","By default, a DataFrame in Pandas is indexed by a sequence of integers starting from 0, but you can also specify a custom index using `.set_index()`. \n","\n","Setting a column as the index can be useful in a number of scenarios, such as when you have a unique identifier for each row in the DataFrame. For example, you might have a column containing unique customer IDs and you might want to set that column as the index of your DataFrame. This allows you to access rows in the DataFrame based on the customer ID, rather than the integer index.\n","\n","The index in pandas is also important because it is used to align data during operations such as merging and concatenating DataFrames. Additionally, the index is used when performing operations like grouping, aggregating, and slicing data.\n","  "]},{"attachments":{},"cell_type":"markdown","id":"cb097a46","metadata":{},"source":["There are two index types in pandas, `.index` and `.columns`, this is because a DataFrame has two axes: rows and columns. The ´.index´ attribute represents the index labels of the rows, while the ´.columns´ attribute represents the column labels of the DataFrame. "]},{"cell_type":"code","execution_count":178,"id":"69efc711","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Columns index  : \n"," Index(['date', 'city', 'country', 'avg_temp_c'], dtype='object') \n","\n","row indexes : \n"," RangeIndex(start=0, stop=16500, step=1) \n","\n"]}],"source":["# Columns index \n","printest('Columns index ',temperatures.columns)\n","\n","# Row index \n","printest('row indexes',temperatures.index)"]},{"attachments":{},"cell_type":"markdown","id":"5e9b7b40","metadata":{},"source":["**Set index**\n","\n","The `.set_index()` method allows to set one or more columns as the index of a DataFrame. Here's an example of how to use the set_index method to set a single column as the index of a DataFrame:"]},{"cell_type":"code","execution_count":179,"id":"9074275a","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>country</th>\n","      <th>avg_temp_c</th>\n","    </tr>\n","    <tr>\n","      <th>city</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Abidjan</th>\n","      <td>2000-01-01</td>\n","      <td>Côte D'Ivoire</td>\n","      <td>27.293</td>\n","    </tr>\n","    <tr>\n","      <th>Abidjan</th>\n","      <td>2000-02-01</td>\n","      <td>Côte D'Ivoire</td>\n","      <td>27.685</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               date        country  avg_temp_c\n","city                                          \n","Abidjan  2000-01-01  Côte D'Ivoire      27.293\n","Abidjan  2000-02-01  Côte D'Ivoire      27.685"]},"execution_count":179,"metadata":{},"output_type":"execute_result"}],"source":["# Set the default index by city\n","temperatures_ind = temperatures.set_index('city')\n","temperatures_ind.head(2)"]},{"attachments":{},"cell_type":"markdown","id":"1ae81ae8","metadata":{},"source":["Setting a column as the index changes the shape and structure of the DataFrame, and so it is no longer part of the regular columns. The `.columns` attribute of a DataFrame returns only the column labels that correspond to the regular columns, not the index.\n","\n","The reason is that the index in a Pandas DataFrame serves a different purpose than the regular columns. The index is used to identify each row in the DataFrame and to support fast lookups and alignment of data between different DataFrames. Setting a column as the index of a DataFrame allows you to access the rows based on the values in that column, rather than the default integer index."]},{"cell_type":"code","execution_count":180,"id":"b9d889dd","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["New row indexes : \n"," Index(['Abidjan', 'Abidjan', 'Abidjan', 'Abidjan', 'Abidjan', 'Abidjan',\n","       'Abidjan', 'Abidjan', 'Abidjan', 'Abidjan',\n","       ...\n","       'Xian', 'Xian', 'Xian', 'Xian', 'Xian', 'Xian', 'Xian', 'Xian', 'Xian',\n","       'Xian'],\n","      dtype='object', name='city', length=16500) \n","\n","new columns index : \n"," Index(['date', 'country', 'avg_temp_c'], dtype='object') \n","\n"]}],"source":["# Row index \n","printest(\"New row indexes\", temperatures_ind.index)\n","\n","# Column index\n","printest('new columns index', temperatures_ind.columns)"]},{"attachments":{},"cell_type":"markdown","id":"04484254","metadata":{},"source":["**Reset index**\n","\n","To undo the set index, we can reset the index with the method `.reset_index()`, or we can exclude permanently the index with `.reset_index(drop = True)`."]},{"cell_type":"code","execution_count":181,"id":"12785fee","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["reset index : \n","       city        date        country  avg_temp_c\n","0  Abidjan  2000-01-01  Côte D'Ivoire      27.293\n","1  Abidjan  2000-02-01  Côte D'Ivoire      27.685 \n","\n","drop index : \n","          date        country  avg_temp_c\n","0  2000-01-01  Côte D'Ivoire      27.293\n","1  2000-02-01  Côte D'Ivoire      27.685 \n","\n"]}],"source":["# Reset the index, keeping its contents\n","printest(\"reset index\",temperatures_ind.reset_index().head(2))\n","\n","# Reset the index, dropping its contents\n","printest(\"drop index\",temperatures_ind.reset_index(drop = True).head(2))"]},{"attachments":{},"cell_type":"markdown","id":"04bb24f8","metadata":{},"source":["**Sort index values**\n","\n","The `.sort_index` method sorts the DataFrame along the index axis and returns a new DataFrame sorted by the index values. By default, the `.sort_index` method sorts the DataFrame in ascending order."]},{"cell_type":"code","execution_count":226,"id":"58de1b81","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                         date  avg_temp_c\n","country     city                         \n","Afghanistan Kabul  2000-01-01       3.326\n","            Kabul  2000-02-01       3.454\n"]}],"source":["# Sort temperatures_ind by index values\n","print(temperatures_ind.sort_index().head(2))"]},{"cell_type":"code","execution_count":224,"id":"3b0854e7","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["               date        country  avg_temp_c\n","city                                          \n","Abidjan  2000-01-01  Côte D'Ivoire      27.293\n","Abidjan  2008-11-01  Côte D'Ivoire      27.302\n"]}],"source":["# Sort temperatures_ind by index values at the city level\n","print(temperatures_ind.sort_index(level=[\"city\"]).head(2))"]},{"cell_type":"code","execution_count":225,"id":"4af8c6a4","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                         date  avg_temp_c\n","country     city                         \n","Afghanistan Kabul  2000-01-01       3.326\n","            Kabul  2000-02-01       3.454\n"]}],"source":["# Set the default index by country and city\n","temperatures_ind = temperatures.set_index([\"country\", \"city\"])\n","\n","# Sort temperatures_ind by country then descending city\n","print(temperatures_ind.sort_index(level=[\"country\", \"city\"], ascending = [True, False]).head(2))"]},{"attachments":{},"cell_type":"markdown","id":"a4f51e5c","metadata":{},"source":["## Subsetting rows\n","\n","There are several ways to subset rows in pandas based on specific criteria.\n","1. Boolean Indexing: use boolean indexing to filter the rows of a DataFrame based on a condition (as previously discussed)\n","2. `.loc`: The `.loc` method allows you to subset rows based on **label values**\n","3. `.iloc`: The `.iloc` method allows you to subset rows based on **integer position** (explained in the next section)"]},{"attachments":{},"cell_type":"markdown","id":"7c56e747","metadata":{},"source":["- **Subset rows with brackets and boolean index**"]},{"cell_type":"code","execution_count":219,"id":"18d7f171","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["             date    city country  avg_temp_c\n","10725  2000-01-01  Moscow  Russia      -7.313\n","10726  2000-02-01  Moscow  Russia      -3.551\n"]}],"source":["# Subset temperatures using square brackets and boolean index\n","print(temperatures[ (temperatures[\"city\"] == \"Moscow\") | (temperatures[\"city\"] == \"Saint Petersburg\")].head(2))"]},{"attachments":{},"cell_type":"markdown","id":"09ee238e","metadata":{},"source":["- **Subset rows with brackets and `.isin` method**"]},{"cell_type":"code","execution_count":220,"id":"42837bbb","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["             date    city country  avg_temp_c\n","10725  2000-01-01  Moscow  Russia      -7.313\n","10726  2000-02-01  Moscow  Russia      -3.551\n"]}],"source":["# Make a list of cities to subset on\n","cities = [\"Moscow\", \"Saint Petersburg\"]\n","# Subset temperatures using square brackets\n","print(temperatures[temperatures['city'].isin(cities)].head(2))"]},{"attachments":{},"cell_type":"markdown","id":"0c7ff58b","metadata":{},"source":["- **Subset rows with `.loc` method (clean way)**\n","\n","The `.loc` method is used to access and manipulate data in a DataFrame by label. **When a column is set as the index of a DataFrame, we can use the `.loc`** method to access and manipulate the data based on the index label."]},{"cell_type":"code","execution_count":222,"id":"6340b85d","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              date country  avg_temp_c\n","city                                  \n","Moscow  2000-01-01  Russia      -7.313\n","Moscow  2000-02-01  Russia      -3.551\n"]}],"source":["# Set the default index by city, .loc only work with indexes\n","temperatures_ind = temperatures.set_index('city')\n","\n","# Subset temperatures_ind using .loc[]\n","print(temperatures_ind.loc[cities].head(2))"]},{"attachments":{},"cell_type":"markdown","id":"61844005","metadata":{},"source":["**Setting multi-level indexes and subseting**\n","\n","Indexes can also be made out of multiple columns, forming a multi-level index (sometimes called a hierarchical index). There is a trade-off to using these.\n","\n","The benefit is that multi-level indexes make it more natural to reason about nested categorical variables. For example, in a clinical trial, you might have control and treatment groups. Then each test subject belongs to one or another group, and we can say that a test subject is nested inside the treatment group. Similarly, in the temperature dataset, the city is located in the country, so we can say a city is nested inside the country.\n","\n","The order of the columns in the MultiIndex is determined by the order in which they are specified in the `.set_index` method, as follows"]},{"cell_type":"code","execution_count":227,"id":"af79a12a","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                             date  avg_temp_c\n","country       city                           \n","Côte D'Ivoire Abidjan  2000-01-01      27.293\n","              Abidjan  2000-02-01      27.685\n"]}],"source":["# Index temperatures by country & city\n","temperatures_ind =  temperatures.set_index([\"country\",\"city\"])\n","print(temperatures_ind.head(2))"]},{"attachments":{},"cell_type":"markdown","id":"89cbf57b","metadata":{},"source":["In this case we must pass a list of tuples to subset multiples rows for the columns transformed into indexes."]},{"cell_type":"code","execution_count":228,"id":"038d8f76","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                              date  avg_temp_c\n","country city                                  \n","Brazil  Rio De Janeiro  2000-01-01      25.974\n","        Rio De Janeiro  2000-02-01      26.699\n"]}],"source":["# List of tuples: Brazil, Rio De Janeiro & Pakistan, Lahore\n","rows_to_keep = [(\"Brazil\", \"Rio De Janeiro\"),(\"Pakistan\",\"Lahore\")]\n","\n","# Subset for rows to keep\n","print(temperatures_ind.loc[rows_to_keep].head(2))"]},{"attachments":{},"cell_type":"markdown","id":"6459317e","metadata":{},"source":["## Slicing with `.loc` and `.iloc` (slicing rows and columns)\n","\n","In pandas, slicing and subsetting refer to the same operation of extracting a portion of a DataFrame. \n","\n","- **Subsetting:** refers to the operation of selecting a portion of a DataFrame based on index values or conditions.\n","- **Slicing:** is a term commonly used in python to refer to the operation of selecting a portion of a sequence (e.g. list, tuple, string, np.array etc.) based on index values."]},{"attachments":{},"cell_type":"markdown","id":"01b94431","metadata":{},"source":["### Slicing with loc\n","\n","Slicing lets you select consecutive elements of an object using `first:last` syntax. DataFrames can be sliced by index values or by row/column number; we'll start with the first case. This involves slicing inside the `.loc[]` method."]},{"attachments":{},"cell_type":"markdown","id":"4ae7333b","metadata":{},"source":["- Compared to slicing lists, there are a few things to remember.\n","\n","    - You can only slice an index if the index is sorted (using `.sort_index()`).\n","    - To slice at the **outer level**, first and last **can be strings**.\n","    - To slice at **inner levels**, first and last **should be tuples**.\n","    - If you pass a single slice to `.loc[]`, it will slice the rows."]},{"attachments":{},"cell_type":"markdown","id":"b2be21ef","metadata":{},"source":["- **Slicing rows**"]},{"cell_type":"code","execution_count":203,"id":"22f70cc8","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                           date  avg_temp_c\n","country  city                              \n","Pakistan Faisalabad  2000-01-01      12.792\n","         Faisalabad  2000-02-01      14.339\n","         Faisalabad  2000-03-01      20.309\n","         Faisalabad  2000-04-01      29.072\n","         Faisalabad  2000-05-01      34.845\n"]}],"source":["# set the index temperatures by country & city\n","temperatures_ind =  temperatures.set_index([\"country\",\"city\"])\n","\n","# Sort the index of temperatures_ind\n","temperatures_srt = temperatures_ind.sort_index()\n","\n","# Subset rows from Pakistan to Russia\n","print(temperatures_srt.loc[\"Pakistan\":\"Russia\"].head())"]},{"cell_type":"code","execution_count":204,"id":"863bbd42","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                      date  avg_temp_c\n","country city                          \n","Mexico  Mexico  2000-01-01      12.694\n","        Mexico  2000-02-01      14.677\n","        Mexico  2000-03-01      17.376\n","        Mexico  2000-04-01      18.294\n","        Mexico  2000-05-01      18.562\n"]}],"source":["# Try to subset rows from Lahore to Moscow\n","print(temperatures_srt.loc[\"Lahore\" : \"Moscow\"].head())"]},{"cell_type":"code","execution_count":205,"id":"5f1e5fd5","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                       date  avg_temp_c\n","country  city                          \n","Pakistan Lahore  2000-01-01      12.792\n","         Lahore  2000-02-01      14.339\n","         Lahore  2000-03-01      20.309\n","         Lahore  2000-04-01      29.072\n","         Lahore  2000-05-01      34.845\n"]}],"source":["# Subset rows from Pakistan, Lahore to Russia, Moscow\n","print(temperatures_srt.loc[(\"Pakistan\", \"Lahore\"):(\"Russia\", \"Moscow\")].head())"]},{"attachments":{},"cell_type":"markdown","id":"34f0cfdd","metadata":{},"source":["- **Slicing rows and columns**\n","\n"," Slice both dimensions at once: `df.loc[:, :]`"]},{"cell_type":"code","execution_count":200,"id":"2f6b408b","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                         date  avg_temp_c\n","country city                             \n","India   Hyderabad  2000-01-01      23.779\n","        Hyderabad  2000-02-01      25.826\n","        Hyderabad  2000-03-01      28.821\n","        Hyderabad  2000-04-01      32.698\n","        Hyderabad  2000-05-01      32.438\n"]}],"source":["# Slice rows from India, Hyderabad to Iraq, Baghdad\n","print(temperatures_srt.loc[(\"India\", \"Hyderabad\"):(\"Iraq\", \"Baghdad\")].head() )"]},{"cell_type":"code","execution_count":201,"id":"a60c19c6","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                         date  avg_temp_c\n","country     city                         \n","Afghanistan Kabul  2000-01-01       3.326\n","            Kabul  2000-02-01       3.454\n","            Kabul  2000-03-01       9.612\n","            Kabul  2000-04-01      17.925\n","            Kabul  2000-05-01      24.658\n"]}],"source":["# Slice columns from date to avg_temp_c\n","print(temperatures_srt.loc[: , \"date\":\"avg_temp_c\" ].head())"]},{"cell_type":"code","execution_count":202,"id":"f973600f","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                         date  avg_temp_c\n","country city                             \n","India   Hyderabad  2000-01-01      23.779\n","        Hyderabad  2000-02-01      25.826\n","        Hyderabad  2000-03-01      28.821\n","        Hyderabad  2000-04-01      32.698\n","        Hyderabad  2000-05-01      32.438\n"]}],"source":["# Slice in both directions at once\n","print(temperatures_srt.loc[ (\"India\", \"Hyderabad\"):(\"Iraq\", \"Baghdad\"), \"date\":\"avg_temp_c\" ].head())"]},{"attachments":{},"cell_type":"markdown","id":"0baeaec0","metadata":{},"source":["- **Slicing time series**\n","  \n","Slicing is particularly useful for time series since it's a common thing to want to filter for data within a date range. Add the date column to the index, then use `.loc[]` to perform the subsetting. The important thing to remember is to keep your dates in ISO 8601 format, that is, \"`yyyy-mm-dd`\" for year-month-day, \"`yyyy-mm`\" for year-month, and \"`yyyy`\" for year."]},{"cell_type":"code","execution_count":212,"id":"a1105ccf","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["           date     city        country  avg_temp_c\n","120  2010-01-01  Abidjan  Côte D'Ivoire      28.270\n","121  2010-02-01  Abidjan  Côte D'Ivoire      29.262\n","122  2010-03-01  Abidjan  Côte D'Ivoire      29.596\n"]}],"source":["# Use Boolean conditions to subset temperatures for rows in 2010 and 2011\n","temperatures_bool = temperatures[(temperatures['date'] >= \"2010-01-01\") & (temperatures['date'] <= \"2011-12-01\")]\n","print(temperatures_bool.head(3))"]},{"cell_type":"code","execution_count":211,"id":"6c3cc60f","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                  city    country  avg_temp_c\n","date                                         \n","2010-01-01  Faisalabad   Pakistan      11.810\n","2010-01-01   Melbourne  Australia      20.016\n","2010-01-01   Chongqing      China       7.921\n"]}],"source":["# Set date as the index and sort the index\n","temperatures_ind = temperatures.set_index(\"date\").sort_index()\n","\n","# Use .loc[] to subset temperatures_ind for rows in 2010 and 2011\n","print(temperatures_ind.loc['2010':'2011'].head(3))"]},{"cell_type":"code","execution_count":210,"id":"7fa0c91d","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                city country  avg_temp_c\n","date                                    \n","2010-08-01  Calcutta   India      30.226\n","2010-08-01      Pune   India      24.941\n","2010-08-01     Izmir  Turkey      28.352\n"]}],"source":["# Use .loc[] to subset temperatures_ind for rows from Aug 2010 to Feb 2011\n","print(temperatures_ind.loc[\"2010-08\":\"2011-02\"].head(3))"]},{"attachments":{},"cell_type":"markdown","id":"0809b679","metadata":{},"source":["### Slicing with iloc\n","\n","The `.iloc` method allows to select rows and columns by their integer-based position. So, `.iloc` only takes integer-based positional arguments and does not accept labels or conditions. If we want to select data based on labels or conditions, then stay with `.loc` method instead."]},{"cell_type":"code","execution_count":216,"id":"fc082b6b","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["         date\n","0  2000-01-01\n","1  2000-02-01\n"]}],"source":["# Get 23rd row, 2nd column (index 22, 1)\n","print(temperatures.iloc[:22,:1].head(2))"]},{"cell_type":"code","execution_count":215,"id":"3988a430","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["         date     city        country  avg_temp_c\n","0  2000-01-01  Abidjan  Côte D'Ivoire      27.293\n","1  2000-02-01  Abidjan  Côte D'Ivoire      27.685\n"]}],"source":["# Use slicing to get the first 5 rows\n","print(temperatures.iloc[:5,:].head(2) )"]},{"cell_type":"code","execution_count":217,"id":"32a356ed","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["         country  avg_temp_c\n","0  Côte D'Ivoire      27.293\n","1  Côte D'Ivoire      27.685\n"]}],"source":["# Use slicing to get columns 3 to 4\n","print(temperatures.iloc[:, [2,3]].head(2))\n"]},{"cell_type":"code","execution_count":218,"id":"b9e17f07","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["         country  avg_temp_c\n","0  Côte D'Ivoire      27.293\n","1  Côte D'Ivoire      27.685\n"]}],"source":["\n","# Use slicing in both directions at once\n","print(temperatures.iloc[:5,[2,3]].head(2))"]},{"attachments":{},"cell_type":"markdown","id":"66bffbf4","metadata":{},"source":["## Working with pivot tables\n","\n","How perform subsetting and calculation on pivot tables"]},{"attachments":{},"cell_type":"markdown","id":"807c85bb","metadata":{},"source":["**Pivot temperature by city and year**\n","\n","It's interesting to see how temperatures for each city change over time—looking at every month results in a big table, which can be tricky to reason about. Instead, let's look at how temperatures change by year.\n","\n","You can access the components of a date (year, month and day) using code of the form \n","- `dataframe[\"column\"].dt.component`: for all component of a date \n","- `dataframe[\"column\"].dt.month` : for month component \n","- `dataframe[\"column\"].dt.year` : for the year component\n","\n","To transform a column in a datetime to use ´dt´ use\n","\n","- `pd.to_datetime(datraframe[\"column\"], format='%Y-%m-%d' )`"]},{"cell_type":"code","execution_count":9,"id":"ec4d60af","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["        date     city        country  avg_temp_c  year\n","0 2000-01-01  Abidjan  Côte D'Ivoire      27.293  2000\n","1 2000-02-01  Abidjan  Côte D'Ivoire      27.685  2000\n"]}],"source":["# define the format of date for the column 'date'\n","temperatures[\"date\"] = pd.to_datetime(temperatures['date'], format='%Y-%m-%d')\n","\n","# Add a year column to temperatures\n","temperatures[\"year\"]= temperatures[\"date\"].dt.year\n","print(temperatures.head(2))"]},{"cell_type":"code","execution_count":12,"id":"0668f3bc","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["        date     city        country  avg_temp_c  year\n","0 2000-01-01  Abidjan  Côte D'Ivoire      27.293  2000\n","1 2000-02-01  Abidjan  Côte D'Ivoire      27.685  2000\n"]}],"source":["# Add a year column to temperatures\n","temperatures[\"year\"]=temperatures[\"date\"].dt.year\n","print(temperatures.head(2))"]},{"cell_type":"code","execution_count":13,"id":"93bec6bc","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["year                     2000       2001       2002       2003       2004  \\\n","country     city                                                            \n","Afghanistan Kabul   15.822667  15.847917  15.714583  15.132583  16.128417   \n","Angola      Luanda  24.410333  24.427083  24.790917  24.867167  24.216167   \n","\n","year                     2005       2006       2007       2008       2009  \\\n","country     city                                                            \n","Afghanistan Kabul   14.847500  15.798500  15.518000  15.479250  15.093333   \n","Angola      Luanda  24.414583  24.138417  24.241583  24.266333  24.325083   \n","\n","year                    2010       2011       2012       2013  \n","country     city                                               \n","Afghanistan Kabul   15.67600  15.812167  14.510333  16.206125  \n","Angola      Luanda  24.44025  24.150750  24.240083  24.553875  \n"]}],"source":["# Pivot avg_temp_c by country and city vs year\n","temp_by_country_city_vs_year = temperatures.pivot_table(values=\"avg_temp_c\", index=[\"country\",\"city\"], columns=\"year\")\n","\n","# See the result\n","print(temp_by_country_city_vs_year.head(2))"]},{"attachments":{},"cell_type":"markdown","id":"980999f5","metadata":{},"source":["**Subsetting pivot tables**\n","\n","A pivot table is just a DataFrame with sorted indexes, so we can use `.loc[]` to slice the pivot table."]},{"cell_type":"code","execution_count":15,"id":"032860b1","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["year                   2000       2001       2002       2003       2004  \\\n","country city                                                              \n","Egypt   Alexandria  20.7445  21.454583  21.456167  21.221417  21.064167   \n","\n","year                     2005       2006      2007    2008     2009  \\\n","country city                                                          \n","Egypt   Alexandria  21.082333  21.148167  21.50775  21.739  21.6705   \n","\n","year                     2010     2011       2012     2013  \n","country city                                                \n","Egypt   Alexandria  22.459583  21.1815  21.552583  21.4385  \n"]}],"source":["# Subset for Egypt to India\n","print(temp_by_country_city_vs_year.loc[\"Egypt\": \"India\"].head(1))"]},{"cell_type":"code","execution_count":16,"id":"651f840a","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["year                2000       2001       2002     2003       2004     2005  \\\n","country city                                                                  \n","Egypt   Cairo  21.486167  22.330833  22.414083  22.1705  22.081917  22.0065   \n","\n","year            2006    2007     2008    2009      2010       2011      2012  \\\n","country city                                                                   \n","Egypt   Cairo  22.05  22.361  22.6445  22.625  23.71825  21.986917  22.48425   \n","\n","year             2013  \n","country city           \n","Egypt   Cairo  22.907  \n"]}],"source":["# Subset for Egypt, Cairo to India, Delhi\n","print(temp_by_country_city_vs_year.loc[(\"Egypt\", \"Cairo\") :(\"India\", \"Delhi\")].head(1))"]},{"cell_type":"code","execution_count":17,"id":"909cd76e","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["year              2005   2006    2007     2008    2009      2010\n","country city                                                    \n","Egypt   Cairo  22.0065  22.05  22.361  22.6445  22.625  23.71825\n"]}],"source":["# Subset in both directions at once\n","print(temp_by_country_city_vs_year.loc[ (\"Egypt\", \"Cairo\") :(\"India\", \"Delhi\"), 2005:2010 ].head(1) )"]},{"attachments":{},"cell_type":"markdown","id":"991a88ab","metadata":{},"source":["**Calculating on a pivot table**\n","\n","Pivot tables are filled with summary statistics, but they are only a first step to finding something insightful. Often you'll need to perform further calculations on them. A common thing to do is to find the rows or columns where the highest or lowest value occurs."]},{"cell_type":"code","execution_count":20,"id":"e43b6149","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["year\n","2000    19.506243\n","2001    19.679352\n","2002    19.855685\n","dtype: float64\n"]}],"source":["# Get the worldwide mean temp by year\n","mean_temp_by_year = temp_by_country_city_vs_year.mean(axis = \"rows\")\n","print(mean_temp_by_year.head(3))"]},{"cell_type":"code","execution_count":22,"id":"5d03d8f3","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["year\n","2013    20.312285\n","dtype: float64\n"]}],"source":["\n","# Filter for the year that had the highest mean temp\n","print(mean_temp_by_year[mean_temp_by_year == mean_temp_by_year.max() ]) \n"]},{"cell_type":"code","execution_count":24,"id":"02443d44","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["country      city     \n","Afghanistan  Kabul        15.541955\n","Angola       Luanda       24.391616\n","Australia    Melbourne    14.275411\n","dtype: float64\n"]}],"source":["\n","# Get the mean temp by city\n","mean_temp_by_city = temp_by_country_city_vs_year.mean(axis= \"columns\")\n","print(mean_temp_by_city.head(3))"]},{"cell_type":"code","execution_count":25,"id":"5575c3a8","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["country  city  \n","China    Harbin    4.876551\n","dtype: float64\n"]}],"source":["# Filter for the city that had the lowest mean temp\n","print(mean_temp_by_city[mean_temp_by_city == mean_temp_by_city.min() ])"]}],"metadata":{"editor":"DataCamp Workspace","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"0743c798041383927c03f3bae5eca888e94e4777f716cdd511cdff96fbdedc02"}}},"nbformat":4,"nbformat_minor":5}
